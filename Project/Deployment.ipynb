{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49b6635e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting streamlit_app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile streamlit_app.py\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.stattools import acf,pacf,adfuller\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "import tensorflow\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import RMSprop,Adam\n",
    "from tensorflow.keras.layers import LSTM,Bidirectional\n",
    "\n",
    "data=pd.read_excel(\"Company stock prices.xlsx\")\n",
    "df2=data[['Date','Close']]\n",
    "df=data[['Date','Close']]\n",
    "df.set_index('Date',inplace=True)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "min_max=MinMaxScaler()\n",
    "df1=min_max.fit_transform(np.array(df))\n",
    "training_size=int(len(df1)*0.75)\n",
    "test_size=len(df1)-training_size\n",
    "train_data,test_data=df1[0:training_size,:],df1[training_size:,:]\n",
    "def create_dataset(dataset,time_step=1):\n",
    "    dataX,dataY=[],[]\n",
    "    for i in range(len(dataset)-time_step):\n",
    "        a=dataset[i:(i+time_step),0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i+ time_step,0])\n",
    "    return np.array(dataX),np.array(dataY)\n",
    "time_step=50\n",
    "x_train,y_train=create_dataset(train_data,time_step)\n",
    "x_test,y_test=create_dataset(test_data,time_step)\n",
    "x_train=x_train.reshape(514,50,1)\n",
    "x_test=x_test.reshape(139,50,1)\n",
    "\n",
    "# Load the saved LSTM model\n",
    "model = keras.models.load_model(\"my_work.h5\")\n",
    "pred=model.predict(x_test)\n",
    "predd=min_max.inverse_transform(pred)\n",
    "y_testt=y_test.reshape(-1,1)\n",
    "y_testt=min_max.inverse_transform(y_testt)\n",
    "y_testt=pd.DataFrame(y_testt)\n",
    "predd=pd.DataFrame(predd)\n",
    "d=data[['Date']][615:-1]\n",
    "dd=d.reset_index()\n",
    "\n",
    "predicted_price = []\n",
    "\n",
    "def stock_prediction(days):\n",
    "    t = x_test[-1]\n",
    "    tt = t.reshape(1, 50, 1)\n",
    "    p = model.predict(tt)\n",
    "    predicted_price.append(p[0])\n",
    "\n",
    "    for i in range(days-1):    \n",
    "        stockValue_list = list(t)\n",
    "        stockValue_list.append(p[0])\n",
    "        testing_array = np.array(stockValue_list[-50:])\n",
    "        p = model.predict(testing_array.reshape(1, 50, 1))\n",
    "        predicted_price.append(p[0])\n",
    "    predicted_pricee=min_max.inverse_transform(predicted_price)\n",
    "    return predicted_pricee\n",
    "b=stock_prediction(263)\n",
    "# Assuming you already have a DataFrame 'stock_prices' with 'Date' and 'Close' columns\n",
    "# If not, you can create it from your existing data\n",
    "\n",
    "# Convert the 'Date' column to a datetime object if it's not already\n",
    "df2['Date'] = pd.to_datetime(df2['Date'])\n",
    "\n",
    "# Find the latest date in your DataFrame\n",
    "latest_date = df2['Date'].max()\n",
    "\n",
    "# Calculate the date one year from the latest date\n",
    "one_year_later = latest_date + pd.DateOffset(years=1)\n",
    "\n",
    "# Create a date range from the latest date to one year later, including only weekdays\n",
    "extended_date_range = pd.date_range(start=latest_date, end=one_year_later, freq='B')\n",
    "\n",
    "# Create a DataFrame with the extended date range\n",
    "extended_stock_prices = pd.DataFrame({'Date': extended_date_range})\n",
    "\n",
    "# Merge the extended date DataFrame with your original stock price data\n",
    "extended_stock_prices = pd.merge(extended_stock_prices, df2, on='Date', how='left')\n",
    "date_col=extended_stock_prices[[\"Date\"]]\n",
    "new_columns={0:\"Close\"}\n",
    "predicted_df=pd.DataFrame(b)\n",
    "predicted_df=predicted_df.rename(columns=new_columns)\n",
    "dfff=pd.concat([date_col,predicted_df],axis=1)\n",
    "dfff=dfff.rename(columns=new_columns)\n",
    "\n",
    "# Streamlit UI\n",
    "st.title(\"LSTM Model Deployment\")\n",
    "date=st.date_input(\"ENTER YOUR DATE HERE\")\n",
    "def _stock_p(date):\n",
    "    resu=dfff[(dfff['Date'])==(date)]\n",
    "    return resu\n",
    "sto=_stock_p(date)\n",
    "st.write(sto)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fe8803",
   "metadata": {},
   "outputs": [],
   "source": [
    "!streamlit run streamlit_app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b321587a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
